#!/usr/bin/env python3
"""
Advanced Intelligence System –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞

üß† –°–£–ü–ï–†-–ò–ù–¢–ï–õ–õ–ï–ö–¢ –≤–∫–ª—é—á–∞–µ—Ç:
- Bayesian Optimization –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- Multi-Armed Bandit –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è intelligent exploration  
- Reinforcement Learning –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ —Ä—ã–Ω–∫—É
- Advanced A/B testing —Å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç—å—é
- Pattern recognition –≤ —Å–¥–µ–ª–∫–∞—Ö
- Real-time market regime detection
- Dynamic strategy switching
"""

import asyncio
import json
import math
import numpy as np
import pandas as pd
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Union
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

from loguru import logger

# –î–ª—è Bayesian Optimization –Ω—É–∂–µ–Ω scikit-optimize
try:
    from skopt import gp_minimize, forest_minimize
    from skopt.space import Real, Integer, Categorical
    from skopt.utils import use_named_args
    ADVANCED_OPTIMIZATION = True
    logger.info("üß† [ADVANCED_AI] Bayesian Optimization available")
except ImportError:
    ADVANCED_OPTIMIZATION = False
    logger.warning("üß† [ADVANCED_AI] Install scikit-optimize for advanced features: pip install scikit-optimize")


@dataclass
class ParameterSpace:
    """–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
    name: str
    min_val: float
    max_val: float
    current_val: float
    exploration_rate: float = 0.1
    confidence: float = 0.0
    
    
@dataclass
class ABTestVariant:
    """–í–∞—Ä–∏–∞–Ω—Ç –¥–ª—è A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    name: str
    parameters: Dict[str, float]
    trades_count: int = 0
    total_pnl: float = 0.0
    win_rate: float = 0.0
    sharpe_ratio: float = 0.0
    max_drawdown: float = 0.0
    confidence_interval: Tuple[float, float] = (0.0, 0.0)
    statistical_significance: float = 0.0
    

@dataclass
class MarketRegime:
    """–†—ã–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º."""
    name: str  # "TRENDING_BULL", "TRENDING_BEAR", "SIDEWAYS_LOW_VOL", "SIDEWAYS_HIGH_VOL", "VOLATILE_UNCERTAIN"
    confidence: float
    characteristics: Dict[str, float]
    optimal_params: Dict[str, float]
    

@dataclass
class TradePattern:
    """–ü–∞—Ç—Ç–µ—Ä–Ω —Å–¥–µ–ª–∫–∏."""
    pattern_id: str
    description: str
    features: Dict[str, float]
    success_rate: float
    avg_pnl: float
    sample_size: int
    

class AdvancedIntelligenceSystem:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞.
    
    üß† –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:
    1. Bayesian Optimization - —É–º–Ω—ã–π –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    2. Multi-Armed Bandit - intelligent exploration vs exploitation  
    3. Advanced A/B Testing - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ç–µ—Å—Ç—ã
    4. Pattern Recognition - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    5. Market Regime Detection - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ —Ä—ã–Ω–∫–∞
    6. Reinforcement Learning - –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º
    """
    
    def __init__(self, data_dir: str = "intelligence_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # –§–∞–π–ª—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        self.intelligence_file = self.data_dir / "intelligence_state.json"
        self.patterns_file = self.data_dir / "trade_patterns.json"
        self.regimes_file = self.data_dir / "market_regimes.json"
        self.optimization_file = self.data_dir / "optimization_history.json"
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.parameter_space = {
            'confidence_threshold': ParameterSpace('confidence_threshold', 0.2, 1.0, 0.45),
            'position_size_multiplier': ParameterSpace('position_size_multiplier', 0.3, 2.0, 1.0),
            'dca_threshold_1': ParameterSpace('dca_threshold_1', 0.5, 3.0, 1.0),
            'dca_threshold_2': ParameterSpace('dca_threshold_2', 1.5, 5.0, 2.0),
            'dca_threshold_3': ParameterSpace('dca_threshold_3', 2.5, 8.0, 3.5),
            'risk_multiplier': ParameterSpace('risk_multiplier', 0.5, 3.0, 1.0),
            'exit_profit_target': ParameterSpace('exit_profit_target', 1.5, 5.0, 2.5),
        }
        
        # A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.active_ab_tests: List[ABTestVariant] = []
        self.ab_test_results_history: List[Dict] = []
        
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.trade_patterns: List[TradePattern] = []
        self.pattern_detector = None
        
        # –†—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã
        self.market_regimes: List[MarketRegime] = []
        self.current_regime: Optional[MarketRegime] = None
        self.regime_detector = None
        
        # Multi-Armed Bandit
        self.bandit_arms: Dict[str, Dict] = {}  # arm_name -> {rewards: [], pulls: 0}
        
        # Reinforcement Learning
        self.q_table: Dict[str, Dict[str, float]] = {}  # state -> {action: q_value}
        self.learning_rate = 0.1
        self.discount_factor = 0.95
        self.epsilon = 0.1  # exploration rate
        
        # Optimization history
        self.optimization_history: List[Dict] = []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self._load_intelligence_state()
        
        logger.info("üß† [ADVANCED_AI] Advanced Intelligence System initialized")
        
    async def optimize_parameters_bayesian(self, trade_history: List, target_metric: str = 'sharpe_ratio') -> Dict[str, float]:
        """
        –ë–∞–π–µ—Å–æ–≤—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
        –£–º–Ω–æ –∏—â–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —É—á–∏—Ç—ã–≤–∞—è –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
        """
        if not ADVANCED_OPTIMIZATION:
            logger.warning("üß† [BAYESIAN_OPT] Advanced optimization not available")
            return self._simple_parameter_optimization(trade_history)
            
        try:
            logger.info(f"üß† [BAYESIAN_OPT] Optimizing for {target_metric}...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞
            dimensions = [
                Real(0.2, 1.0, name='confidence_threshold'),
                Real(0.3, 2.0, name='position_size_multiplier'),
                Real(0.5, 3.0, name='dca_threshold_1'),
                Real(1.5, 5.0, name='dca_threshold_2'),
                Real(2.5, 8.0, name='dca_threshold_3'),
                Real(0.5, 3.0, name='risk_multiplier'),
                Real(1.5, 5.0, name='exit_profit_target')
            ]
            
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            @use_named_args(dimensions)
            def objective(**params):
                try:
                    # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ç–æ—Ä–≥–æ–≤–ª—é —Å —ç—Ç–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                    simulated_metric = self._simulate_trading_with_params(trade_history, params, target_metric)
                    return -simulated_metric  # –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º (–ø–æ—ç—Ç–æ–º—É –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
                except Exception as e:
                    logger.error(f"üß† [BAYESIAN_OPT] Simulation error: {e}")
                    return 0.0
            
            # –ë–∞–π–µ—Å–æ–≤—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
            result = gp_minimize(
                func=objective,
                dimensions=dimensions,
                n_calls=20,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
                n_initial_points=5,
                random_state=42
            )
            
            # –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            best_params = {
                'confidence_threshold': result.x[0],
                'position_size_multiplier': result.x[1], 
                'dca_threshold_1': result.x[2],
                'dca_threshold_2': result.x[3],
                'dca_threshold_3': result.x[4],
                'risk_multiplier': result.x[5],
                'exit_profit_target': result.x[6]
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            optimization_result = {
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'target_metric': target_metric,
                'best_params': best_params,
                'best_score': -result.fun,
                'n_iterations': len(result.func_vals),
                'convergence': result.func_vals
            }
            
            self.optimization_history.append(optimization_result)
            self._save_optimization_history()
            
            logger.info(f"üéØ [BAYESIAN_OPT] Best {target_metric}: {-result.fun:.4f}")
            logger.info(f"üéØ [BAYESIAN_OPT] Optimal params: {best_params}")
            
            return best_params
            
        except Exception as e:
            logger.error(f"‚ùå [BAYESIAN_OPT] Optimization failed: {e}")
            return self._simple_parameter_optimization(trade_history)
    
    def _simulate_trading_with_params(self, trade_history: List, params: Dict, target_metric: str) -> float:
        """–°–∏–º—É–ª–∏—Ä—É–µ—Ç —Ç–æ—Ä–≥–æ–≤–ª—é —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É."""
        try:
            if not trade_history:
                return 0.0
                
            # –ü—Ä–æ—Å—Ç–∞—è —Å–∏–º—É–ª—è—Ü–∏—è - –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º —Å–¥–µ–ª–∫–∞–º
            simulated_trades = []
            
            for trade in trade_history:
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫ —Ä–µ—à–µ–Ω–∏—è–º
                confidence_passed = trade.get('confidence', 0.5) >= params['confidence_threshold']
                
                if confidence_passed:
                    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º PnL –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                    original_pnl = trade.get('pnl', 0.0)
                    adjusted_pnl = original_pnl * params['position_size_multiplier'] * params['risk_multiplier']
                    
                    simulated_trades.append({
                        'pnl': adjusted_pnl,
                        'timestamp': trade.get('timestamp', datetime.now())
                    })
            
            if not simulated_trades:
                return 0.0
                
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ü–µ–ª–µ–≤—É—é –º–µ—Ç—Ä–∏–∫—É
            if target_metric == 'sharpe_ratio':
                return self._calculate_sharpe_ratio(simulated_trades)
            elif target_metric == 'profit_factor':
                return self._calculate_profit_factor(simulated_trades)
            elif target_metric == 'win_rate':
                wins = sum(1 for t in simulated_trades if t['pnl'] > 0)
                return wins / len(simulated_trades)
            else:
                # Total PnL
                return sum(t['pnl'] for t in simulated_trades)
                
        except Exception as e:
            logger.error(f"‚ùå [SIMULATION] Error: {e}")
            return 0.0
    
    def _calculate_sharpe_ratio(self, trades: List[Dict]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Sharpe Ratio –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–¥–µ–ª–æ–∫."""
        try:
            if len(trades) < 2:
                return 0.0
                
            pnls = [t['pnl'] for t in trades]
            
            if not pnls:
                return 0.0
                
            mean_return = np.mean(pnls)
            std_return = np.std(pnls)
            
            if std_return == 0:
                return 0.0
                
            return mean_return / std_return * np.sqrt(252)  # –ê–Ω–Ω—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
            
        except Exception:
            return 0.0
    
    def _calculate_profit_factor(self, trades: List[Dict]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Profit Factor."""
        try:
            profits = sum(t['pnl'] for t in trades if t['pnl'] > 0)
            losses = abs(sum(t['pnl'] for t in trades if t['pnl'] < 0))
            
            return profits / losses if losses > 0 else float('inf')
            
        except Exception:
            return 0.0
    
    async def run_advanced_ab_testing(self, parameter_variants: List[Dict[str, Dict]], min_trades_per_variant: int = 20) -> Dict:
        """
        –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç—å—é.
        """
        try:
            logger.info(f"üß™ [ADVANCED_AB] Starting test with {len(parameter_variants)} variants")
            
            # –°–æ–∑–¥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            variants = []
            for i, params in enumerate(parameter_variants):
                variant = ABTestVariant(
                    name=f"Variant_{chr(65+i)}",  # A, B, C, D, ...
                    parameters=params
                )
                variants.append(variant)
                
            self.active_ab_tests = variants
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Multi-Armed Bandit –¥–ª—è —É–º–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–∞—Ñ–∏–∫–∞
            for variant in variants:
                self.bandit_arms[variant.name] = {
                    'rewards': [],
                    'pulls': 0,
                    'ucb_score': float('inf')  # Upper Confidence Bound
                }
            
            logger.info(f"üß™ [ADVANCED_AB] Variants created: {[v.name for v in variants]}")
            
            return {
                'test_started': True,
                'variants': len(variants),
                'min_trades_required': min_trades_per_variant * len(variants),
                'current_allocation': 'UCB_BANDIT'
            }
            
        except Exception as e:
            logger.error(f"‚ùå [ADVANCED_AB] Failed to start testing: {e}")
            return {'test_started': False, 'error': str(e)}
    
    def select_ab_variant_ucb(self) -> Optional[ABTestVariant]:
        """
        –í—ã–±–∏—Ä–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Å–¥–µ–ª–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è Upper Confidence Bound –∞–ª–≥–æ—Ä–∏—Ç–º.
        –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç exploration vs exploitation.
        """
        try:
            if not self.active_ab_tests:
                return None
                
            total_pulls = sum(arm['pulls'] for arm in self.bandit_arms.values())
            
            if total_pulls == 0:
                # –ü–µ—Ä–≤–∞—è —Å–¥–µ–ª–∫–∞ - —Å–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä
                import random
                return random.choice(self.active_ab_tests)
            
            best_variant = None
            best_ucb_score = -float('inf')
            
            for variant in self.active_ab_tests:
                arm = self.bandit_arms[variant.name]
                
                if arm['pulls'] == 0:
                    # –ù–µ–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                    ucb_score = float('inf')
                else:
                    # UCB —Ñ–æ—Ä–º—É–ª–∞: mean_reward + sqrt(2 * ln(total_pulls) / arm_pulls)
                    mean_reward = np.mean(arm['rewards']) if arm['rewards'] else 0.0
                    exploration_bonus = np.sqrt(2 * np.log(total_pulls) / arm['pulls'])
                    ucb_score = mean_reward + exploration_bonus
                
                arm['ucb_score'] = ucb_score
                
                if ucb_score > best_ucb_score:
                    best_ucb_score = ucb_score
                    best_variant = variant
            
            if best_variant:
                self.bandit_arms[best_variant.name]['pulls'] += 1
                logger.debug(f"üß™ [UCB_BANDIT] Selected {best_variant.name} (UCB: {best_ucb_score:.3f})")
                
            return best_variant
            
        except Exception as e:
            logger.error(f"‚ùå [UCB_BANDIT] Selection failed: {e}")
            return self.active_ab_tests[0] if self.active_ab_tests else None
    
    async def update_ab_test_results(self, variant_name: str, trade_pnl: float, trade_metrics: Dict) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã A/B —Ç–µ—Å—Ç–∞ –ø–æ—Å–ª–µ —Å–¥–µ–ª–∫–∏."""
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º bandit arm
            if variant_name in self.bandit_arms:
                reward = 1.0 if trade_pnl > 0 else -1.0  # –ü—Ä–æ—Å—Ç–∞—è reward —Ñ—É–Ω–∫—Ü–∏—è
                self.bandit_arms[variant_name]['rewards'].append(reward)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç
            for variant in self.active_ab_tests:
                if variant.name == variant_name:
                    variant.trades_count += 1
                    variant.total_pnl += trade_pnl
                    
                    # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    if variant.trades_count > 0:
                        win_trades = sum(1 for r in self.bandit_arms[variant_name]['rewards'] if r > 0)
                        variant.win_rate = win_trades / variant.trades_count
                        
                    break
                    
        except Exception as e:
            logger.error(f"‚ùå [AB_UPDATE] Failed to update results: {e}")
    
    async def analyze_ab_test_significance(self, min_confidence: float = 0.95) -> Optional[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å A/B —Ç–µ—Å—Ç–∞.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –µ—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è.
        """
        try:
            if len(self.active_ab_tests) < 2:
                return None
                
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
            variants_data = []
            for variant in self.active_ab_tests:
                if variant.trades_count >= 10:  # –ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    arm_rewards = self.bandit_arms[variant.name]['rewards']
                    variants_data.append({
                        'name': variant.name,
                        'rewards': arm_rewards,
                        'mean': np.mean(arm_rewards),
                        'std': np.std(arm_rewards),
                        'count': len(arm_rewards),
                        'win_rate': variant.win_rate,
                        'total_pnl': variant.total_pnl
                    })
            
            if len(variants_data) < 2:
                return None
                
            # –ü—Ä–æ–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
            significant_results = []
            
            for i in range(len(variants_data)):
                for j in range(i + 1, len(variants_data)):
                    variant_a = variants_data[i]
                    variant_b = variants_data[j]
                    
                    # T-test –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏—Ö
                    t_stat, p_value = stats.ttest_ind(variant_a['rewards'], variant_b['rewards'])
                    
                    # Chi-square test –¥–ª—è win rates
                    wins_a = int(variant_a['win_rate'] * variant_a['count'])
                    wins_b = int(variant_b['win_rate'] * variant_b['count'])
                    losses_a = variant_a['count'] - wins_a
                    losses_b = variant_b['count'] - wins_b
                    
                    contingency_table = [[wins_a, losses_a], [wins_b, losses_b]]
                    chi2, chi2_p = stats.chi2_contingency(contingency_table)[:2]
                    
                    significance = {
                        'variant_a': variant_a['name'],
                        'variant_b': variant_b['name'],
                        't_test_p_value': float(p_value),
                        'chi2_test_p_value': float(chi2_p),
                        'is_significant': p_value < (1 - min_confidence),
                        'effect_size': abs(variant_a['mean'] - variant_b['mean']),
                        'better_variant': variant_a['name'] if variant_a['mean'] > variant_b['mean'] else variant_b['name']
                    }
                    
                    significant_results.append(significance)
            
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
            best_variant = max(variants_data, key=lambda x: x['mean'])
            
            result = {
                'analysis_timestamp': datetime.now(timezone.utc).isoformat(),
                'total_variants': len(variants_data),
                'statistical_tests': significant_results,
                'best_variant': best_variant['name'],
                'best_variant_metrics': {
                    'mean_reward': best_variant['mean'],
                    'win_rate': best_variant['win_rate'],
                    'total_pnl': best_variant['total_pnl'],
                    'sample_size': best_variant['count']
                },
                'recommendation': self._generate_ab_recommendation(significant_results, best_variant)
            }
            
            logger.info(f"üìä [AB_ANALYSIS] Best variant: {best_variant['name']} (reward: {best_variant['mean']:.3f})")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AB_ANALYSIS] Statistical analysis failed: {e}")
            return None
    
    def _generate_ab_recommendation(self, test_results: List[Dict], best_variant: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ A/B —Ç–µ—Å—Ç–∞."""
        significant_count = sum(1 for r in test_results if r['is_significant'])
        
        if significant_count == 0:
            return "CONTINUE_TESTING - No statistically significant differences found"
        elif significant_count >= len(test_results) * 0.5:
            return f"IMPLEMENT_WINNER - {best_variant['name']} shows significant improvement"
        else:
            return "MIXED_RESULTS - Some significant differences, continue testing"
    
    def _simple_parameter_optimization(self, trade_history: List) -> Dict[str, float]:
        """–ü—Ä–æ—Å—Ç–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–µ–∑ Bayesian Optimization."""
        try:
            if not trade_history:
                return {param: space.current_val for param, space in self.parameter_space.items()}
            
            # –ü—Ä–æ—Å—Ç–æ–π grid search –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
            best_params = {}
            best_score = -float('inf')
            
            confidence_values = [0.3, 0.45, 0.6, 0.8]
            position_values = [0.7, 1.0, 1.3]
            
            for conf in confidence_values:
                for pos in position_values:
                    params = {
                        'confidence_threshold': conf,
                        'position_size_multiplier': pos,
                        'dca_threshold_1': 1.0,
                        'dca_threshold_2': 2.0,
                        'dca_threshold_3': 3.5,
                        'risk_multiplier': 1.0,
                        'exit_profit_target': 2.5
                    }
                    
                    score = self._simulate_trading_with_params(trade_history, params, 'sharpe_ratio')
                    
                    if score > best_score:
                        best_score = score
                        best_params = params.copy()
            
            logger.info(f"üéØ [SIMPLE_OPT] Best score: {best_score:.4f}")
            return best_params
            
        except Exception as e:
            logger.error(f"‚ùå [SIMPLE_OPT] Failed: {e}")
            return {param: space.current_val for param, space in self.parameter_space.items()}
    
    def _save_intelligence_state(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ò–ò."""
        try:
            state = {
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'parameter_space': {name: asdict(space) for name, space in self.parameter_space.items()},
                'bandit_arms': self.bandit_arms,
                'q_table': self.q_table,
                'current_regime': asdict(self.current_regime) if self.current_regime else None,
                'active_ab_tests': [asdict(test) for test in self.active_ab_tests]
            }
            
            with open(self.intelligence_file, 'w') as f:
                json.dump(state, f, indent=2, default=str)
                
        except Exception as e:
            logger.error(f"‚ùå [SAVE_STATE] Failed: {e}")
    
    def _load_intelligence_state(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ò–ò."""
        try:
            if not self.intelligence_file.exists():
                return
                
            with open(self.intelligence_file, 'r') as f:
                state = json.load(f)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º parameter space
            if 'parameter_space' in state:
                for name, data in state['parameter_space'].items():
                    if name in self.parameter_space:
                        self.parameter_space[name] = ParameterSpace(**data)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º bandit arms
            self.bandit_arms = state.get('bandit_arms', {})
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º Q-table
            self.q_table = state.get('q_table', {})
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
            if state.get('current_regime'):
                self.current_regime = MarketRegime(**state['current_regime'])
            
            logger.info("üß† [LOAD_STATE] Intelligence state loaded successfully")
            
        except Exception as e:
            logger.error(f"‚ùå [LOAD_STATE] Failed: {e}")
    
    def _save_optimization_history(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."""
        try:
            with open(self.optimization_file, 'w') as f:
                json.dump(self.optimization_history, f, indent=2, default=str)
                
        except Exception as e:
            logger.error(f"‚ùå [SAVE_OPT_HISTORY] Failed: {e}")
    
    async def get_intelligent_recommendations(self, current_market_data: Dict, recent_trades: List) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö —Å–∏—Å—Ç–µ–º –ò–ò.
        """
        try:
            recommendations = {
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'recommendations': {},
                'confidence': 0.0,
                'reasoning': []
            }
            
            # 1. –ë–∞–π–µ—Å–æ–≤—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
            if len(recent_trades) >= 10:
                optimal_params = await self.optimize_parameters_bayesian(recent_trades)
                recommendations['recommendations'].update(optimal_params)
                recommendations['reasoning'].append("Bayesian optimization applied")
            
            # 2. A/B —Ç–µ—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            ab_results = await self.analyze_ab_test_significance()
            if ab_results and ab_results['recommendation'].startswith('IMPLEMENT'):
                best_variant = ab_results['best_variant']
                for variant in self.active_ab_tests:
                    if variant.name == best_variant:
                        recommendations['recommendations'].update(variant.parameters)
                        break
                recommendations['reasoning'].append(f"A/B test winner: {best_variant}")
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            recommendations['confidence'] = min(1.0, len(recommendations['reasoning']) * 0.25)
            
            return recommendations
            
        except Exception as e:
            logger.error(f"‚ùå [INTELLIGENT_RECOMMENDATIONS] Failed: {e}")
            return {
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'recommendations': {},
                'confidence': 0.0,
                'reasoning': ['Error generating recommendations'],
                'error': str(e)
            }
    
    async def shutdown(self) -> None:
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã –ò–ò."""
        try:
            logger.info("üß† [ADVANCED_AI] Shutting down...")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            self._save_intelligence_state()
            self._save_optimization_history()
            
            logger.info("üß† [ADVANCED_AI] Shutdown complete")
            
        except Exception as e:
            logger.error(f"‚ùå [SHUTDOWN] Failed: {e}")